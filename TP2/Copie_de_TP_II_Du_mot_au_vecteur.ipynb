{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8_B-KEr9T3vE"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vv-vAt24VSKt"
      },
      "source": [
        "# TP II. Du mot au vecteur\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. TF-IDF** <br>\n",
        "Questions : <br>\n",
        "\n",
        "- Qu'est-ce que c'est le score TF-IDF ?\n",
        "- Comment calcule-t-on le score TF-IDF ?\n",
        "- Quelle est la différence entre les représentations BOW et TF-IDF\n"
      ],
      "metadata": {
        "id": "NATjGr1Q9HsN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'objectif de cette première partie est d'apprendre à implementer le score TF-IDF pour un corpus. Pour cela il faudrait créer 3 fonctions : computeTF(), computeIDF(), computeTFIDF(), les tester et créer une dictionnaire sous le format {doc1:{word1_tfidf:0},doc2:{word1_tfidf:0}}. Il faudrait également ajouter des fonctions supplémentaires pour nettoyer les données."
      ],
      "metadata": {
        "id": "D00auaAf9fy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = \"Philip Nel takes a fascinating look into the key aspects of Seuss's career - his poetry, politics, art, marketing, and place in the popular imagination.\" \"Nel argues convincingly that Dr. Seuss is one of the most influential poets in America. His nonsense verse, like that of Lewis Carroll and Edward Lear, has changed language itself, giving us new words like nerd. And Seuss's famously loopy artistic style - what Nel terms an energetic cartoon surrealism - has been equally important, inspiring artists like filmmaker Tim Burton and illustrator Lane Smith. --from back cover\"\n",
        "doc2 = \"This resource includes twelve principles in understanding small church worship, fifteen practices for planning worship with fewer than 100 people, and suggestions for congregational study.\"\n",
        "doc3 = \"At a time when America's faculties of taste and judgment—along with the sense of the sacred and shameful—have become utterly vacant, Rochelle Gurstein's The Repeal of Reticence delivers an important and troubling warning. Covering landmark developments in America's modern culture and law, she charts the demise of what was dismissively called gentility in the face of First Amendment triumphs for journalists, sex educators, and novelists—from Margaret Sanger's advocacy of birth control to Judge Woolsey's celebrated defense of Ulysses. Weaving together a study of the legal debates over obscenity and free speech with a cultural study of the critics and writers who framed the issues, Gurstein offers a trenchant reconsideration of the sacred value of privacy.\"\n",
        "doc4 = \"The DK Eyewitness Travel Guide: Eastern and Central Europe is your indispensable guide to this beautiful part of the world. The fully updated guide includes unique cutaways, floorplans and reconstructions of the must-see sites, plus street-by-street maps of all the fascinating cities and towns. The new-look guide is also packed with photographs and illustrations leading you straight to the best attractions on offer. The uniquely visual DK Eyewitness Travel Guide: Eastern and Central Europe will help you to discover everything region-by-region; from local festivals and markets to day trips around the countryside. Detailed listings will guide you to the best hotels, restaurants, bars and shops for all budgets, whilst detailed practical information will help you to get around, whether by train, bus or car. Plus, DK's excellent insider tips and essential local information will help you explore every corner of Eastern and Central Europe effortlessly. DK Eyewitness Travel Guide: Eastern and Central Europe showing you what others only tell you.\"\n",
        "doc5 = \"A striking collection of presidential portraits from the National Portrait Gallery, this volume encapsulates the spirit of the most powerful office in the world. America's Presidents showcases the nation's largest collection of portraits of all the presidents beyond the White House's own, capturing the permanent exhibition that lies at the heart of the Portrait Gallery's mission to tell the American story through the individuals who have shaped it. The book explores presidential imagery through portraits ranging from the traditional, such as the iconic and newly restored Lansdowne portrait of George Washington by Gilbert Stuart, to the contemporary, such as Elaine de Kooning's colorful depiction of John F. Kennedy. Many of the featured portraits reveal much about the sitter, such as the intimate rendering of an informal George W. Bush by Robert Anderson and the fanciful, mosaic-like Chuck Close image of Bill Clinton. Some tell us more about the artist, such as the likeness of Franklin Delano Roosevelt that Douglas Chandor planned to include in a larger work about peace that would commemorate Roosevelt's Yalta meeting with wartime Allied leaders Winston Churchill and Joseph Stalin. Works in other media, including sculptures and daguerreotypes, round out the presidential collection. Lively narratives accompany each piece, exploring the president's background and biography as well as the work's artistic and historical significance. Taken together, the portraits are a powerful visual exploration of the history of the highest office in the land and the diverse men who have held it.\"\n",
        "doc6 = \"This book offers 30 North American wildlife illustrations and 10 border designs to use in woodburning projects. Large ready-to-use designs are provided in both line and tonal patterns. The author includes tips on transferring patterns, plus advice on segmenting and manipulating the images to create your own custom designs.\"\n",
        "doc7 = \"The futures seems to be full of promise and excitement. Certainly at no time for nearly a millenium and a half has the opportunity for genuine theology been greater, since the ground has been cleared in the remarkable way of the old dualist and atomistic modes of thought that have plagued theology for centuries. It is, therefore, up to us as theologians to develop theology on its own proper ground in this scientific context, if only because this is the kind of life and culture, and the kind of theology that can support the message of the Gospel to mankind, as, in touch with the advances of natural science, theology comes closer and closer to a real understanding of the creation as it came from the hand of God.\""
      ],
      "metadata": {
        "id": "6xFEjIovgFTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data():\n",
        "  pass"
      ],
      "metadata": {
        "id": "8rTYeEeDdl-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def computeTF():\n",
        "  pass"
      ],
      "metadata": {
        "id": "GNt05wDo-SOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def computeIDF():\n",
        "  pass"
      ],
      "metadata": {
        "id": "MK251oi3-cTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def computeTFIDF():\n",
        "  pass"
      ],
      "metadata": {
        "id": "HfbiDAK4-lmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_doc_dict():\n",
        "  pass"
      ],
      "metadata": {
        "id": "uBf6NUvqG2gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_final_dict():\n",
        "  pass"
      ],
      "metadata": {
        "id": "8RlP1wY_Gx7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbmglOnBW18Y"
      },
      "source": [
        "## La startup Huggingface\n",
        "\n",
        "- https://huggingface.co/\n",
        "- franco-américaine\n",
        "- coeur = librairie open-source de modèles de NLP\n",
        "  - en particulier : le module **transformers** : entraînement / utilisation de modèles de langue pré-entraînés, basé sur architecture de type transformers\n",
        "  - centralise l'accès à des **dizaines de modèles pré-entraînés**, par diverses équipes dans le monde\n",
        "- modèle économique? voir modèles typiques https://blog.timescale.com/blog/how-open-source-software-makes-money-time-series-database-f3e4be409467/\n",
        "  - en l'occurrence, \"inference API\" https://huggingface.co/pricing, utilisation des modèles pré-entraînés via une API rapide\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he0kPLTMXH3U"
      },
      "source": [
        "# Tokenisation en sous-mots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gi7TlyaOF40"
      },
      "source": [
        "import torch\n",
        "\n",
        "# import (après éventuelle installation) du module transformers\n",
        "try:\n",
        "  from transformers import AutoModel, AutoTokenizer\n",
        "except ImportError:\n",
        "  !pip install transformers\n",
        "  !pip install sacremoses\n",
        "\n",
        "  from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C5ipFz6s-bW"
      },
      "source": [
        "# On commence par travailler avec le modèle BERT multilingue\n",
        "# cf. liste des modèles dispos : https://huggingface.co/transformers/pretrained_models.html\n",
        "\n",
        "# chargement du tokenizer associé au modèle bert-base-multilingual-cased\n",
        "tokenizer_bert = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "# les classes AutoTokenizer / AutoModel / AutoConfig permettent de \"deviner\" la classe exacte\n",
        "# des différents modèles, d'après leur nom \n",
        "# (le nom \"bert-base-multilingual-cased\" est associé à un BertModel, BertTokenizer et BertConfig)\n",
        "print(type(tokenizer_bert))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltQDGxa4PSVi"
      },
      "source": [
        "# version lisible de la tokenization, phrase par phrase\n",
        "sent = \"Aujourd'hui, j'essaie de comprendre les intringuants transformers.\"\n",
        "print(tokenizer_bert.tokenize(sent))\n",
        "print(tokenizer_bert.convert_tokens_to_ids(tokenizer.tokenize(sent)))\n",
        "# équivalent à :\n",
        "print(tokenizer_bert.encode(sent, add_special_tokens=False))\n",
        "    \n",
        "# et avec les symboles spéciaux :\n",
        "print(\"Avec symb spéciaux:\")\n",
        "print(tokenizer_bert.encode(sent, add_special_tokens=True))\n",
        "print(tokenizer_bert.convert_ids_to_tokens(tokenizer_bert.encode(sent, add_special_tokens=True)))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4r53MnZxG1C"
      },
      "source": [
        "print(tokenizer_bert(sent))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0j0IKT2vr9z"
      },
      "source": [
        "# TODO: cherchez comment décoder et encoder une paire de phrases (cf. modèle BERT est entraîné sur des paires)\n",
        "sent2 = ''\n",
        "\n",
        "\n",
        "# docs \n",
        "# https://huggingface.co/transformers/main_classes/tokenizer.html\n",
        "# https://huggingface.co/transformers/internal/tokenization_utils.html\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Affichez la version encodée et décodée"
      ],
      "metadata": {
        "id": "k4k2Rqu4eyFb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k95YAiwMVSLB"
      },
      "source": [
        "# TODO: utilisez maintenant le tokenizer Camembert,\n",
        "# (cf. liste des modèles dispos : https://huggingface.co/transformers/pretrained_models.html)\n",
        "#       et comparez sa tokenization avec celle de BERT multilingue.\n",
        "#       Repérez les ids de tokens spéciaux.\n",
        "\n",
        "tokenizer_camembert = AutoTokenizer.from_pretrained(\"camembert-base\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(tokenizer_camembert))"
      ],
      "metadata": {
        "id": "z4IWUT0ukEP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent = \"Aujourd'hui, j'essaie de comprendre les intringuants transformers.\""
      ],
      "metadata": {
        "id": "THtHpC-217gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q** : Quelles sont les différences entre le tokeniseur le tokeniseur BERT Multilangue et le tokeniseur Camembert ? <br>\n",
        "**R** : "
      ],
      "metadata": {
        "id": "VuG6Jte_fC7h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trouvez les réponses"
      ],
      "metadata": {
        "id": "QRC2zKzmfYyw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVMTA9Oi7yep"
      },
      "source": [
        "print('Beginning token id: ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn4h0dSd8FI5"
      },
      "source": [
        "print('Pad token id: ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilQ-Fslc8g0e"
      },
      "source": [
        "print('Cls token id: ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8Fy3-xz93Em"
      },
      "source": [
        "print('Mask token id: ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHoA2cfS-VeB"
      },
      "source": [
        "print('Unk token id: ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UT1OiJoVSLH"
      },
      "source": [
        "texts = [\"eoari8 é§ êêçth\",\n",
        "         \"J'essaie de comprendre les transformers.\", \n",
        "         \"Nous comprenions bien le cours.\",\n",
        "         \"Le code comprend des erreurs.\", \n",
        "         \"Il n'a pas bien compris le nouveau cours!\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ztc71_6VSLM"
      },
      "source": [
        "# version lisible de la tokenization, phrase par phrase\n",
        "for sent in texts:\n",
        "    print(tokenizer_camembert.encode(sent, add_special_tokens=True))\n",
        "    print(tokenizer_camembert.convert_ids_to_tokens(tokenizer_camembert.encode(sent, add_special_tokens=True)))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN4VCbnFVSLS"
      },
      "source": [
        "# TODO: produire les tenseurs d'entrée du modèle, pour une liste de phrases\n",
        "\n",
        "# on utilise pour cela un appel à tokenizer()\n",
        "\n",
        "\n",
        "# étudiez la méthode __call__ dont hérite CamembertTokenizer (méthode __call__ de PreTrainedTokenizer)\n",
        "# https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.PreTrainedTokenizer\n",
        "\n",
        "# et appliquez la méthode sur la variable texts, en choisissant les options pour\n",
        "# tronquer / padder toutes les séquences à la longueur totale 10 (tokens spéciaux compris)\n",
        "\n",
        "# la sortie de tokenizer() est un dictionnaire\n",
        "# TODO: expliquez à quoi correspond chaque élément du dictionnaire de sortie\n",
        "#       et faites un affichage pour chaque clé/valeur du dictionnaire\n",
        "\n",
        "# quel est l'id du token de padding ?\n",
        "\n",
        "#encodings = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoqJN28s1PLN"
      },
      "source": [
        "#encodings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fujPt6LS1Bex"
      },
      "source": [
        "#encodings['input_ids']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1BEHl1K1Lz6"
      },
      "source": [
        "#encodings['token_type_ids']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQwqhryd1Ta-"
      },
      "source": [
        "#encodings['attention_mask']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6Siya7I1sF2"
      },
      "source": [
        "print('Pad token id: ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_B-KEr9T3vE"
      },
      "source": [
        "# Propagation avant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_HqVUPsy9KS"
      },
      "source": [
        "# TODO : utilisez AutoModel.from_pretrained pour charger le modèle pré-entraîîné Camembert\n",
        "\n",
        "\n",
        "# Affichez la classe du modèle\n",
        "\n",
        "model = AutoModel.from_pretrained(\"camembert-base\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9KuB0X8U8Xu"
      },
      "source": [
        "# On considère les phrases de la variable texts supra comme un batch d'entrée.\n",
        "# Un appel à model() va appeler la méthode forward de modèle\n",
        "\n",
        "# TODO: Etudiez la méthode __forward__ ici\n",
        "#       https://huggingface.co/docs/transformers/model_doc/camembert\n",
        "#       et utilisez la pour obtenir le vecteur contextuel associé \n",
        "#       au token <s> de chaque séquence de la variable texts\n",
        "\n",
        "# NB: __forward__ prend des tenseurs torch.Tensor en entrée\n",
        "\n",
        "# indications : utilisez return_dict = True, et étudiez les clés du dico de sortie\n",
        "# étudiez la shape du ou des tenseurs de sortie\n",
        "# NB: inutile de donner en entrée les masques d'attention (voir infra)\n",
        "\n",
        "#contextual_representations = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ti8EqJQwRvn"
      },
      "source": [
        "# Etude des poids d'auto-attention :\n",
        "# on vérifie que les tokens <pad> ne reçoivent pas de poids dans l'auto-attention\n",
        "\n",
        "# On se concentre sur la phrase 4, qui termine par 2 tokens de padding\n",
        "# donc on ne garde que\n",
        "# tensor_encodings['input_ids'][3].view(1,10)\n",
        "\n",
        "# TODO: affichez les poids d'auto-attention pour le 4eme token de la phrase (\"comprend\", position=3)\n",
        "#        - à la dernière couche\n",
        "#        - sur la première tête\n",
        "\n",
        "# Indications: utilisez output_attentions=True\n",
        "#   et récupérez ainsi les poids d'auto-attention \n",
        "#   Etudiez la shape des attentions\n",
        "#   et déduisez-en le nombre de couches du modèle \n",
        "#                  le nombre de têtes d'attention y a-t-il dans chaque couche (cf. multi-head transformer)?\n",
        "\n",
        "#   Récupérez la matrice 10x10 (cf. 10 tokens dans la phrase)\n",
        "#   correspondant aux poids d'auto-attention à la dernière couche, pour la première tête\n",
        "\n",
        "#   en utilisant la méthode sum, étudiez si ce sont les lignes ou les colonnes qui somment à 1\n",
        "#   et en déduire où sont les poids d'auto-attention du token \"comprend\" (position 3)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O-GwWUiwJD4"
      },
      "source": [
        "#L'attention dernière couche\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojlakwGhx7r1"
      },
      "source": [
        "#L'attention dernière couche, première tête\n",
        "#On fait un squeeze pour éliminier dimension batch size\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXwBzvKowTt3"
      },
      "source": [
        "matrix1010"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h20ElmnJwgZg"
      },
      "source": [
        "matrix1010.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5f_JryCzazU"
      },
      "source": [
        "#Somme colonnes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH-kjYM-ziBb"
      },
      "source": [
        "#Somme lignes\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}